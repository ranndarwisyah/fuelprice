# -*- coding: utf-8 -*-
"""dashboard 5 testing experiments_ fuel price 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15xoTB3GOjGrwRBavweSKtds4Rc4ytJ1q

# **EXTRACT, LOAD DATA**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from keras.optimizers import Adam, Nadam, SGD, RMSprop
from sklearn.metrics import mean_squared_error, mean_absolute_error
from datetime import datetime
import requests
from tabulate import tabulate

# Load the dataset
url = 'https://docs.google.com/spreadsheets/d/10oV8o1Lq18QZihsR6YoGSV16zK7EYQTmHGJ2W9hIJ_I/export?format=csv'
data = pd.read_csv(url)
print(tabulate(data, headers='keys', tablefmt='pretty', showindex=False))

print(len(data))  # Total number of rows

"""# **PREPROCESSINGS:**
# 1. Handling Missing values
# 2. Normalization
# 3. Outlier detection
# 4. Stability / Stationary
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from statsmodels.tsa.stattools import adfuller
from tabulate import tabulate

# Replace empty strings with NaN
columns_to_clean = ['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']

for col in columns_to_clean:
    data[col].replace('', np.nan, inplace=True)

# Convert percentage values to numeric
def clean_percentage_column(column):
    column = column.replace('%', '', regex=True)  # Remove percentage symbols
    return pd.to_numeric(column, errors='coerce')  # Convert to numeric

for col in columns_to_clean:
    data[col] = np.log1p(clean_percentage_column(data[col]) / 100)  # log(1 + x)


# Handle missing values (fill using forward and backward fill)
data.fillna(method='ffill', limit=1, inplace=True)
data.fillna(method='bfill', limit=1, inplace=True)

# Drop remaining NaN values
data.dropna(inplace=True)

# Ensure there are no infinite values
data.replace([np.inf, -np.inf], np.nan, inplace=True)
data.dropna(inplace=True)

# Normalize features
scaler = MinMaxScaler(feature_range=(0, 1))
data[columns_to_clean] = scaler.fit_transform(data[columns_to_clean])

# Outlier detection using IQR method
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])

for col in columns_to_clean:
    remove_outliers(data, col)

# Ensure final dataset has no NaNs or infinite values
data.replace([np.inf, -np.inf], np.nan, inplace=True)
data.dropna(inplace=True)

# Stationarity check using Augmented Dickey-Fuller test
def check_stationarity(series):
    if series.nunique() == 1:
        print(f"Skipping ADF test for '{series.name}' as it has constant values.\n")
        return

    result = adfuller(series)
    print(f'ADF Statistic for {series.name}: {result[0]:.4f}')
    print(f'p-value: {result[1]:.4f}')
    if result[1] < 0.05:
        print("Data is stationary.\n")
    else:
        print("Data is non-stationary. Differencing may be needed.\n")

for col in columns_to_clean:
    check_stationarity(data[col])

# Remove duplicates
data = data.drop_duplicates()

# Display processed data
print(tabulate(data, headers='keys', tablefmt='pretty', showindex=False))

data = data.sort_values(by=['Countries', 'Date']).reset_index(drop=True)
data['Gasoline\none week'] = data.groupby('Countries')['Gasoline\none week'].pct_change(periods=1)
data['Gasoline\nthree months'] = data.groupby('Countries')['Gasoline\nthree months'].pct_change(periods=1)
data['Diesel\none week'] = data.groupby('Countries')['Diesel\none week'].pct_change(periods=1)
data['Diesel\nthree months'] = data.groupby('Countries')['Diesel\nthree months'].pct_change(periods=1)
print(tabulate(data, headers='keys', tablefmt='pretty', showindex=False))

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data[['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']])  # Assign scaled_data here
print("Checking for NaN values in scaled_data:")
print(pd.DataFrame(scaled_data).isnull().sum())

scaled_data = pd.DataFrame(scaled_data).dropna().values  # Drop NaN rows

import pandas as pd
import numpy as np
from tabulate import tabulate

# Assume X and y are your NumPy arrays created from create_sequences
# For demonstration, let's create some dummy data:
sequence_length = 30
num_sequences = 10
X_dummy = np.random.rand(num_sequences, sequence_length)
y_dummy = np.random.rand(num_sequences, 1) # y is typically 1D or (num_sequences, 1)

# --- How to make headings appear ---

# 1. For X_df (the sequences):
# Create a list of column names. For sequences, these might be "Step_0", "Step_1", etc.
x_column_names = [f"Feature_{i}" for i in range(X_dummy.shape[1])] # Or "Step_0", "Step_1", etc.
X_df = pd.DataFrame(X_dummy, columns=x_column_names)

# 2. For y_df (the targets):
y_df = pd.DataFrame(y_dummy, columns=["Target_Value"]) # Give it a meaningful name

# Now, print them with tabulate
print("X with Headings:\n", tabulate(X_df, headers='keys', tablefmt='pretty', showindex=False))
print("\ny with Headings:\n", tabulate(y_df, headers='keys', tablefmt='pretty', showindex=False))

"""# **MODELING**

# **MAIN MODELING**
"""

import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.losses import Huber
import os

# Assuming 'data' is already loaded - you'll need to load your dataset here
# data = pd.read_csv('your_fuel_data.csv')  # Uncomment and modify as needed

# Handle missing values in the data
data = data.dropna()

# Get feature names for later use
feature_names = ['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']

# Sort data by country and date to ensure time order
data = data.sort_values(by=['Countries', 'Date']).reset_index(drop=True)

# IMPROVEMENT 1: Use per-country scaling
# Instead of scaling all countries together, scale each country separately
scaled_data = data.copy()
countries = data['Countries'].unique()
scalers = {}

for country in countries:
    country_mask = data['Countries'] == country
    country_data = data.loc[country_mask, feature_names]

    # Only create scaler if enough data
    if len(country_data) > 10:  # Arbitrary threshold
        scaler = StandardScaler()  # Use StandardScaler instead of MinMaxScaler
        scaled_values = scaler.fit_transform(country_data)
        scaled_data.loc[country_mask, feature_names] = scaled_values
        scalers[country] = scaler

# IMPROVEMENT 2: Use a longer sequence length
sequence_length = 12  # Increased from 4 to capture more temporal patterns

# Initialize containers
X, y = [], []
country_names = []
dates = []

# Create sequences PER country
for country in countries:
    country_data = scaled_data[scaled_data['Countries'] == country]
    values = country_data[feature_names].values

    # Skip countries with insufficient data points
    if len(values) <= sequence_length:
        continue

    # Store dates for later visualization
    country_dates = country_data['Date'].values

    for i in range(len(values) - sequence_length):
        seq = values[i:i+sequence_length]
        target = values[i+sequence_length]

        # Only add sequences and targets with no NaN values
        if not np.isnan(seq).any() and not np.isnan(target).any():
            X.append(seq)
            y.append(target)
            country_names.append(country)
            dates.append(country_dates[i+sequence_length])

# Convert to arrays
X = np.array(X)
y = np.array(y)
country_names = np.array(country_names)
dates = np.array(dates)

# Verify no NaN values in training data
assert not np.isnan(X).any(), "X still contains NaN values"
assert not np.isnan(y).any(), "y still contains NaN values"

# IMPROVEMENT 3: Use a time-based split instead of random
# Sort everything by date
sort_indices = np.argsort(dates)
X = X[sort_indices]
y = y[sort_indices]
country_names = country_names[sort_indices]
dates = dates[sort_indices]

# Define the split point (80% for training)
split_index = int(len(X) * 0.8)

# Perform the time series split
X_train = X[:split_index]
X_test = X[split_index:]
y_train = y[:split_index]
y_test = y[split_index:]
country_names_train = country_names[:split_index]
country_names_test = country_names[split_index:]
dates_train = dates[:split_index]
dates_test = dates[split_index:]

# Build the LSTM model with Dropout
def build_model(input_shape):
    model = Sequential()
    # First LSTM layer
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.3))  # Added Dropout after the first LSTM layer (30% dropout rate)

    # Second LSTM layer
    model.add(LSTM(50, return_sequences=False))  # return_sequences=False for the last LSTM layer
    model.add(Dropout(0.3))  # Added Dropout after the second LSTM layer

    # Dense layers
    model.add(Dense(25, activation='relu'))
    model.add(Dropout(0.2))  # Added Dropout before the final output layer (20% dropout rate)

    # Output layer for regression - Fixed: should match y dimensions
    model.add(Dense(y_train.shape[1]))  # Output layer for regression

    return model

input_shape = (X_train.shape[1], X_train.shape[2])
model = build_model(input_shape)

# IMPROVEMENT 5: Use a higher initial learning rate with decay - Fixed optimizer syntax
model.compile(
    optimizer=Adam(learning_rate=0.001),  # Fixed: removed extra parentheses
    loss=Huber(delta=0.5),  # Reduced delta for Huber loss to be more sensitive to outliers
    metrics=['mae', 'mse', tf.keras.metrics.RootMeanSquaredError()]
)

model.summary()

# IMPROVEMENT 6: Enhanced callbacks
checkpoint_path = "fuel_price_model/"
os.makedirs(checkpoint_path, exist_ok=True)  # Create directory if it doesn't exist
checkpoint_file = os.path.join(checkpoint_path, "cp.ckpt.weights.h5")

model_checkpoint = ModelCheckpoint(
    filepath=checkpoint_file,
    save_weights_only=True,
    monitor='val_loss',
    mode='min',
    save_best_only=True
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,  # Adjusted: Reduced patience significantly
    min_delta=0.0001,  # Added: Minimum change to qualify as an improvement
    restore_best_weights=True
)

lr_reduction = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=2,  # Adjusted: Slightly more aggressive patience for LR reduction
    min_lr=0.00001,
    verbose=1
)

# IMPROVEMENT 7: Fixed sample weights calculation
# Removed problematic sample weights for regression
# For regression, we don't typically use class weights

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=150,  # Increased epochs since we have early stopping
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping, lr_reduction, model_checkpoint],
    verbose=1
    # Removed sample_weight parameter as it was incorrectly implemented for regression
)

# Evaluate the model
test_results = model.evaluate(X_test, y_test, verbose=1)
test_loss = test_results[0]
test_mae = test_results[1]
test_mse = test_results[2]
test_rmse = test_results[3]

print(f"Test MSE: {test_mse:.4f}, Test MAE: {test_mae:.4f}, Test RMSE: {test_rmse:.4f}")

# Make predictions
y_pred = model.predict(X_test)

# IMPROVEMENT 8: Inverse transform predictions for each country using the country-specific scaler
y_test_original = np.zeros_like(y_test)
y_pred_original = np.zeros_like(y_pred)

for i, country in enumerate(country_names_test):
    if country in scalers:
        # Fixed: Handle the reshape properly for multi-dimensional output
        y_test_original[i] = scalers[country].inverse_transform(y_test[i].reshape(1, -1))
        y_pred_original[i] = scalers[country].inverse_transform(y_pred[i].reshape(1, -1))

# Calculate metrics on the original scale
mse = mean_squared_error(y_test_original, y_pred_original)
mae = mean_absolute_error(y_test_original, y_pred_original)
rmse = math.sqrt(mse)
print(f"MSE on original scale: {mse:.4f}")
print(f"MAE on original scale: {mae:.4f}")
print(f"RMSE on original scale: {rmse:.4f}")

# Create a DataFrame to display the tabular results
def create_prediction_table(y_actual, y_predicted, countries, feature_names):
    results = []
    for i in range(len(y_actual)):
        row = {'Countries': countries[i]}  # Add country name
        for j, feature in enumerate(feature_names):
            row[f'{feature} (Actual %)'] = f"{y_actual[i, j]:.2f}%"
            row[f'{feature} (Forecasted %)'] = f"{y_predicted[i, j]:.2f}%"
            row[f'{feature} (Error %)'] = f"{y_predicted[i, j] - y_actual[i, j]:.2f}%"
        results.append(row)
    return pd.DataFrame(results)

# Create and display prediction table (showing just first 10 rows for brevity)
prediction_table = create_prediction_table(y_test_original, y_pred_original, country_names_test, feature_names)
print("\nPredicted Fuel Price Changes (%)")
display(prediction_table)  # Fixed: changed display() to print()

# Function to plot predictions vs actual values with optional smoothing and zoom
def plot_predictions(y_actual, y_predicted, feature_names, title, smooth=True, zoom_last_n=100):
    plt.figure(figsize=(15, 10))

    for i in range(y_actual.shape[1]):
        plt.subplot(2, 2, i + 1)

        # Convert to pandas Series for smoothing
        actual_series = pd.Series(y_actual[:, i])
        predicted_series = pd.Series(y_predicted[:, i])

        # Apply rolling average smoothing if enabled
        if smooth:
            actual_series = actual_series.rolling(window=10).mean()
            predicted_series = predicted_series.rolling(window=10).mean()

        # Zoom in if specified
        if zoom_last_n and len(actual_series) > zoom_last_n:
            actual_series = actual_series[-zoom_last_n:]
            predicted_series = predicted_series[-zoom_last_n:]

        # Plot
        plt.plot(actual_series, label='Actual (Smoothed)' if smooth else 'Actual')
        plt.plot(predicted_series, label='Forecasted (Smoothed)' if smooth else 'Forecasted')

        plt.title(f'{title} - {feature_names[i]}')
        plt.xlabel('Time Step (Countries Sampling)')
        plt.ylabel('Change (%)')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.show()

# IMPROVEMENT 9: Enhanced visualization for model comparison
def plot_training_history(history):
    metrics = ['loss', 'mae', 'mse', 'root_mean_squared_error']
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    axes = axes.flat

    for i, metric in enumerate(metrics):
        ax = axes[i]
        ax.plot(history.history[metric], label=f'Training {metric}')
        ax.plot(history.history[f'val_{metric}'], label=f'Validation {metric}')
        ax.set_title(f'Training and Validation {metric.upper()}')
        ax.set_xlabel('Epochs')
        ax.set_ylabel(metric.upper())
        ax.legend()
        ax.grid(True)

    plt.tight_layout()
    plt.show()

# Plot improved training history visualization
plot_training_history(history)

# IMPROVEMENT 10: Enhanced country-specific prediction visualization
def plot_predictions_per_country(y_true, y_pred, countries, dates, feature_names, save_dir=None):
    unique_countries = np.unique(countries)

    for country in unique_countries:
        indices = np.where(countries == country)[0]
        if len(indices) < 5:  # Skip countries with very few test points
            continue

        actual = y_true[indices]
        predicted = y_pred[indices]
        country_dates = dates[indices]

        fig, axs = plt.subplots(len(feature_names), 1, figsize=(12, 4 * len(feature_names)))
        if len(feature_names) == 1:
            axs = [axs]

        for i, feature in enumerate(feature_names):
            # Calculate error metrics for this feature
            feature_mse = mean_squared_error(actual[:, i], predicted[:, i])
            feature_mae = mean_absolute_error(actual[:, i], predicted[:, i])
            feature_rmse = np.sqrt(feature_mse)

            axs[i].plot(actual[:, i], label='Actual', color='blue', marker='o', markersize=4)
            axs[i].plot(predicted[:, i], label='Forecast', color='orange', marker='x', markersize=4)

            # Add error bands
            axs[i].fill_between(
                range(len(actual[:, i])),
                predicted[:, i] - feature_mae,
                predicted[:, i] + feature_mae,
                color='orange', alpha=0.2, label='Â±MAE Range'
            )

            axs[i].set_title(f'{feature} - {country} (RMSE: {feature_rmse:.4f}, MAE: {feature_mae:.4f})')
            axs[i].set_ylabel('Percentage Change')
            axs[i].set_xlabel('Time Steps')
            axs[i].legend()
            axs[i].grid(True)

        plt.tight_layout()

        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            plt.savefig(f"{save_dir}/{country.replace(' ', '_')}_forecasted_vs_actual.png")
            plt.close()
        else:
            plt.show()

# Plot country-specific predictions
plot_predictions_per_country(
    y_test_original,
    y_pred_original,
    country_names_test,
    dates_test,
    feature_names,
    save_dir="improved_prediction_plots"
)

# IMPROVEMENT 11: Feature importance analysis - Fixed function reference
def analyze_feature_importance():
    """
    Create a simple feature importance analysis by training models with one feature removed at a time
    """
    base_rmse = rmse
    importance_scores = []

    for i in range(X_train.shape[2]):
        # Create a copy with one feature zeroed out
        X_train_modified = X_train.copy()
        X_test_modified = X_test.copy()

        X_train_modified[:, :, i] = 0
        X_test_modified[:, :, i] = 0

        # Train a smaller model for quicker evaluation
        temp_model = build_model(input_shape)  # Fixed: use the correct function name
        temp_model.compile(optimizer=Adam(learning_rate=0.0005), loss=Huber(delta=0.5), metrics=['mae'])

        # Use fewer epochs for speed
        temp_model.fit(
            X_train_modified, y_train,
            epochs=50,  # Reduced epochs for speed
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=0
        )

        # Evaluate
        temp_pred = temp_model.predict(X_test_modified)

        # Convert to original scale
        temp_pred_original = np.zeros_like(temp_pred)
        for j, country in enumerate(country_names_test):
            if country in scalers:
                temp_pred_original[j] = scalers[country].inverse_transform(temp_pred[j].reshape(1, -1))

        # Calculate metrics
        temp_mse = mean_squared_error(y_test_original, temp_pred_original)
        temp_rmse = math.sqrt(temp_mse)

        importance_scores.append({
            'feature': feature_names[i],
            'rmse_without_feature': temp_rmse,
            'importance_score': temp_rmse - base_rmse
        })

    return importance_scores

# Uncomment to run feature importance analysis (takes time)
# importance_results = analyze_feature_importance()
# print("Feature Importance Analysis:")
# for result in importance_results:
#     print(f"{result['feature']}: {result['importance_score']:.4f}")

# Plot predictions
plot_predictions(y_test_original, y_pred_original, feature_names, 'LSTM Forecast vs Actual', smooth=True, zoom_last_n=100)

"""Why it's limited to 3.0 (approximately):

The loop that generates the plots has this condition:

if len(indices) < 20:  # Use 20 as the threshold
    continue
Use code with caution
This condition skips countries with fewer than 20 data points. It's possible that the countries included in your plots have only a few data points after applying this filter, resulting in a limited x-axis range.
"""

import os
import matplotlib.pyplot as plt
import glob
from IPython.display import Image, display
import numpy as np  # Import numpy for np.unique()

# Create folder to save plots
output_dir = "plots"
os.makedirs(output_dir, exist_ok=True)

# Define unique_countries using country_names_test
unique_countries = np.unique(country_names_test) # Get unique countries from country_names_test

# Loop to plot and save
for i, country in enumerate(unique_countries):
    try:
        # Check if y_test_inverse and predictions_inverse have enough elements
        if i < len(y_test_original) and i < len(y_pred_original):
            actual = y_test_original[i].flatten()
            predicted = y_pred_original[i].flatten()
            time_steps = np.arange(len(actual))  # Explicit x-axis

            plt.figure(figsize=(12, 4))  # Wider frame
            plt.plot(time_steps, actual, label='Actual')
            plt.plot(time_steps, predicted, label='Predicted')
            plt.title(f'{country} - Gasoline & Diesel Price % Change')
            plt.xlabel('Time Step')
            plt.ylabel('Percentage Change')
            plt.legend()
            plt.tight_layout()


            # Save the plot
            filename = f"{country.replace(' ', '_')}_prediction_plot.png"
            plt.savefig(os.path.join(output_dir, filename))

            # Show plot inline
            plt.show()
        else:
            print(f"Skipping {country}: index out of bounds for actual/predicted values")
    except IndexError:
        print(f"Skipping {country}: index out of bounds")

# Display all saved plots at the end
for file in sorted(glob.glob("plots/*.png")):
    display(Image(filename=file))

# Save the prediction table to a CSV file
prediction_table.to_csv('predicted_fuel_price_changes.csv', index=False)

print("Predicted fuel price changes saved to 'predicted_fuel_price_changes.csv'")

"""# **DASHBOARD**"""

!pip install dash plotly pandas numpy scikit-learn dash-bootstrap-components
!pip install jupyter_dash

# Modified Dashboard Code - LSTM Predictions vs Current Data Comparison

import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import dash
from dash import dcc, html, Input, Output, State, dash_table
import dash_bootstrap_components as dbc
from datetime import datetime, timedelta
# The following imports might not be strictly necessary for the dashboard
# if the model is already trained and loaded, but are kept from your original code.
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler # Used in your preprocessing
from sklearn.metrics import mean_absolute_error, mean_squared_error
import base64
import io
import warnings
warnings.filterwarnings('ignore')

# Assume create_prediction_table is defined above this class
# as it's used in __init__
def create_prediction_table(y_actual, y_predicted, countries, feature_names):
    results = []
    for i in range(len(y_actual)):
        row = {'Countries': countries[i]}  # Add country name
        for j, feature in enumerate(feature_names):
            row[f'{feature} (Actual %)'] = f"{y_actual[i, j]:.2f}%"
            row[f'{feature} (Forecasted %)'] = f"{y_predicted[i, j]:.2f}%"
            row[f'{feature} (Error %)'] = f"{y_predicted[i, j] - y_actual[i, j]:.2f}%"
        results.append(row)
    return pd.DataFrame(results)


class FuelPriceDashboard:
    def __init__(self, historical_data_for_model, y_test_original, y_pred_original, country_names_test, feature_names, scalers, model, dates_test):
        # Data for modeling (already heavily preprocessed: log1p, pct_change, scaled)
        self.historical_data_for_model = historical_data_for_model.copy()
        # Ensure Date column in historical_data_for_model is datetime
        if not pd.api.types.is_datetime64_any_dtype(self.historical_data_for_model['Date']):
            self.historical_data_for_model['Date'] = pd.to_datetime(self.historical_data_for_model['Date'], dayfirst=True, errors='coerce')

        self.y_test_original = y_test_original
        self.y_pred_original = y_pred_original
        self.country_names_test = country_names_test
        self.feature_names = feature_names # This refers to ['Gasoline\none week', ...]
        self.dates_test = dates_test # Store test dates for time series plots

        # Store the model and scalers for potential future multi-step forecasting
        self.model = model
        self.scalers = scalers
        # Assuming sequence_length is available from your model training setup
        # You might need to pass this as an argument if it's not global
        # For this example, I'll set a dummy value if not explicitly passed
        self.sequence_length = 12 # Ensure this matches your model's training sequence_length

        # Create the prediction table from LSTM results
        self.prediction_table = create_prediction_table(y_test_original, y_pred_original, country_names_test, feature_names)


        # --- Load and preprocess raw data specifically for display (Current Changes) ---
        url = 'https://docs.google.com/spreadsheets/d/10oV8o1Lq18QZihsR6YoGSV16zK7EYQTmHGJ2W9hIJ_I/export?format=csv'
        raw_data_temp = pd.read_csv(url)

        columns_for_display = ['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']

        # Basic cleaning for display data: convert percentages to float, handle NaNs, parse date
        for col in columns_for_display:
            raw_data_temp[col].replace('', np.nan, inplace=True) # Replace empty strings with NaN
            # Convert to string first to ensure .str.replace() works, then to numeric
            raw_data_temp[col] = raw_data_temp[col].astype(str).str.replace('%', '', regex=False)
            raw_data_temp[col] = pd.to_numeric(raw_data_temp[col], errors='coerce')

        raw_data_temp['Date'] = pd.to_datetime(raw_data_temp['Date'], dayfirst=True, errors='coerce')

        # Fill NaNs for display data to ensure continuous lines in plots
        raw_data_temp.fillna(method='ffill', inplace=True)
        raw_data_temp.fillna(method='bfill', inplace=True)
        raw_data_temp.dropna(inplace=True) # Final drop if any rows still have NaNs

        self.raw_historical_data = raw_data_temp.sort_values(by=['Countries', 'Date']).reset_index(drop=True)
        # --- End of raw data loading for display ---

    def get_countries(self):
        """Get list of available countries from both raw data and prediction table."""
        raw_countries = set(self.raw_historical_data['Countries'].unique())
        prediction_countries = set(self.prediction_table['Countries'].unique())
        # Return countries that appear in both datasets
        common_countries = raw_countries.intersection(prediction_countries)
        return sorted(list(common_countries))

    def get_fuel_types_options(self):
        """Get list of available fuel types for the dropdown."""
        return [{'label': feature.replace('\n', ' ').title(), 'value': feature} for feature in self.feature_names]

    def get_current_price_changes(self, selected_country):
        """Get the latest actual price changes from the RAW GlobalPetrolPrice data for a country."""
        if selected_country and not self.raw_historical_data.empty:
            # Use raw_historical_data for current changes
            country_data = self.raw_historical_data[self.raw_historical_data['Countries'] == selected_country].copy()

            if not country_data.empty:
                country_data = country_data.sort_values('Date')
                latest_data = country_data.iloc[-1]  # Get the most recent row

                current_changes_data = []
                for feature in self.feature_names: # Use model's feature names to check in raw data
                    if feature in latest_data:
                        change_value = latest_data[feature]
                        fuel_display_name = feature.replace('\n', ' ').title()
                        current_changes_data.append({
                            'Fuel Type': fuel_display_name,
                            'Current Price Change (%)': f"{change_value:.2f}%", # Display raw percentage
                            'Last Updated': latest_data['Date'].strftime('%Y-%m-%d') if pd.notna(latest_data['Date']) else 'N/A'
                        })

                changes_df = pd.DataFrame(current_changes_data)
                return changes_df
        return pd.DataFrame()

    def get_lstm_predictions(self, selected_country):
        """Get LSTM predictions for a specific country."""
        if selected_country and not self.prediction_table.empty:
            country_predictions = self.prediction_table[self.prediction_table['Countries'] == selected_country]

            if not country_predictions.empty:
                # Get the most recent prediction for this country
                latest_prediction = country_predictions.iloc[-1]

                prediction_data = []
                for feature in self.feature_names:
                    fuel_display_name = feature.replace('\n', ' ').title()
                    forecasted_col = f'{feature} (Forecasted %)'

                    if forecasted_col in latest_prediction:
                        prediction_data.append({
                            'Fuel Type': fuel_display_name,
                            'LSTM Forecasted (%)': latest_prediction[forecasted_col],
                        })

                return pd.DataFrame(prediction_data)

    def create_comparison_table(self, selected_country):
        """Create a merged table comparing current data with LSTM predictions."""
        current_df = self.get_current_price_changes(selected_country)
        lstm_df = self.get_lstm_predictions(selected_country)

        if current_df.empty or lstm_df.empty:
            return pd.DataFrame()

        # Merge the dataframes on Fuel Type
        merged_df = pd.merge(current_df, lstm_df, on='Fuel Type', how='outer')

        # Reorder columns for better presentation
        column_order = ['Fuel Type', 'Current Price Change (%)', 'LSTM Forecasted (%)', 'Last Updated']
        merged_df = merged_df.reindex(columns=[col for col in column_order if col in merged_df.columns])

        return merged_df

    def create_comparison_chart(self, selected_country):
        """Create a comparison chart between current data and LSTM predictions."""
        comparison_data = self.create_comparison_table(selected_country)

        if comparison_data.empty:
            return go.Figure()

        fig = go.Figure()

        fuel_types = comparison_data['Fuel Type'].tolist()

        # Extract numeric values from percentage strings
        def extract_numeric(value_str):
            if pd.isna(value_str) or value_str == '':
                return 0
            try:
                return float(str(value_str).replace('%', ''))
            except:
                return 0

        current_values = [extract_numeric(val) for val in comparison_data['Current Price Change (%)'].tolist()]
        lstm_forecasted = [extract_numeric(val) for val in comparison_data['LSTM Forecasted (%)'].tolist()]

        # Add bars for current data
        fig.add_trace(go.Bar(
            name='Current Data',
            x=fuel_types,
            y=current_values,
            marker_color='#667eea',
            text=[f"{val:.2f}%" for val in current_values],
            textposition='auto',
        ))

        # Add bars for LSTM forecasted
        fig.add_trace(go.Bar(
            name='LSTM Forecasted',
            x=fuel_types,
            y=lstm_forecasted,
            marker_color='#38ef7d',
            text=[f"{val:.2f}%" for val in lstm_forecasted],
            textposition='auto',
        ))


        return fig

    # --- New Methods for Time Series Chart ---
    def get_time_series_data(self, selected_country, selected_feature):
        """
        Retrieves actual and forecasted time series data for a specific country and feature
        from the test set.
        """
        if not selected_country or not selected_feature or self.y_test_original is None or self.y_pred_original is None or self.country_names_test is None or self.dates_test is None:
            return pd.DataFrame()

        # Find the index of the selected feature in feature_names
        try:
            feature_idx = self.feature_names.index(selected_feature)
        except ValueError:
            return pd.DataFrame() # Feature not found

        # Filter test data for the selected country
        country_mask = (self.country_names_test == selected_country)

        # Ensure masks are applied correctly and result in non-empty arrays
        if not np.any(country_mask):
            return pd.DataFrame()

        # Get dates, actuals, and predictions for the selected country and feature
        dates_filtered = self.dates_test[country_mask]
        actuals_filtered = self.y_test_original[country_mask, feature_idx]
        predictions_filtered = self.y_pred_original[country_mask, feature_idx]

        # Create a DataFrame
        time_series_df = pd.DataFrame({
            'Date': pd.to_datetime(dates_filtered),
            'Actual (%)': actuals_filtered,
            'Forecasted (%)': predictions_filtered
        })

        # Sort by date to ensure correct line plotting
        time_series_df = time_series_df.sort_values(by='Date').reset_index(drop=True)
        return time_series_df

    def create_time_series_chart(self, selected_country, selected_feature):
        """
        Creates a line graph showing historical actual vs. LSTM forecasted values over time
        for a specific country and fuel type.
        """
        feature_display_name = selected_feature.replace('\n', ' ').title()
        time_series_df = self.get_time_series_data(selected_country, selected_feature)

        if time_series_df.empty:
            fig = go.Figure()
            fig.update_layout(
                title=f"No Time Series Data for {feature_display_name} in {selected_country}",
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)',
                font=dict(color='#2c3e50'),
                xaxis={'visible': False},
                yaxis={'visible': False},
                annotations=[{
                    'text': "No data available for the selected combination.",
                    'xref': "paper",
                    'yref': "paper",
                    'x': 0.5,
                    'y': 0.5,
                    'xanchor': 'center',
                    'yanchor': 'middle',
                    'showarrow': False,
                    'font': {'size': 16, 'color': '#6c757d'}
                }]
            )
            return fig

        fig = go.Figure()

        # Add Actuals line
        fig.add_trace(go.Scatter(
            x=time_series_df['Date'],
            y=time_series_df['Actual (%)'],
            mode='lines+markers',
            name='Historical Actual (%)',
            line=dict(color='#007bff', width=2),
            marker=dict(size=4)
        ))

        # Add Forecasted line
        fig.add_trace(go.Scatter(
            x=time_series_df['Date'],
            y=time_series_df['Forecasted (%)'],
            mode='lines+markers',
            name='LSTM Forecasted (%)',
            line=dict(color='#28a745', width=2, dash='dot'), # Dotted line for forecast
            marker=dict(size=4)
        ))

        fig.update_layout(
            title=f"ðŸ“ˆ Historical Actual vs. LSTM Forecasted - {feature_display_name} in {selected_country}",
            xaxis_title="Date",
            yaxis_title="Price Change (%)",
            hovermode="x unified",
            legend_title="Legend",
            template="plotly_white",
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#2c3e50'),
            xaxis=dict(
                tickformat="%b %Y",
                showgrid=True,
                gridcolor='rgba(0,0,0,0.1)'
            ),
            yaxis=dict(
                showgrid=True,
                gridcolor='rgba(0,0,0,0.1)'
            ),
            margin=dict(l=40, r=40, t=80, b=40), # Adjust margins for better fit
            height=500 # Set a fixed height for consistency
        )

        return fig

# Initialize the dashboard with the data from the notebook
# Ensure 'model' and 'dates_test' are passed during initialization
# Assuming 'model' and 'dates_test' are available from your main script scope
dashboard = FuelPriceDashboard(data, y_test_original, y_pred_original, country_names_test, feature_names, scalers, model, dates_test)

# Initialize Dash app
from jupyter_dash import JupyterDash
app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# Enhanced CSS (kept the same as before for consistency)
app.index_string = '''
<!DOCTYPE html>
<html>
    <head>
        {%metas%}
        <title>Fuel Price LSTM Analysis Dashboard</title>
        {%favicon%}
        {%css%}
        <style>
            body {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                min-height: 100vh;
            }
            .main-header {
                text-align: center;
                color: white;
                margin-bottom: 30px;
                font-weight: bold;
                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
                font-size: 2.5rem;
            }
            .card {
                background: rgba(255, 255, 255, 0.95);
                backdrop-filter: blur(10px);
                border: none;
                border-radius: 15px;
                box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
                margin-bottom: 20px;
                transition: transform 0.3s ease;
            }
            .card:hover {
                transform: translateY(-5px);
            }
            .card-header {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                border-radius: 15px 15px 0 0 !important;
                font-weight: bold;
                font-size: 1.1rem;
                padding: 15px 20px;
                border: none;
            }
            .dash-table-container {
                border-radius: 10px;
                overflow: hidden;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            .Select-control {
                border-radius: 10px !important;
                border: 2px solid #e9ecef !important;
                transition: all 0.3s ease !important;
            }
            .Select-control:hover {
                border-color: #667eea !important;
            }
            .container-fluid {
                padding: 20px;
            }
            .disclaimer {
                background: rgba(255, 255, 255, 0.9);
                padding: 20px;
                border-radius: 15px;
                border-left: 5px solid #17a2b8;
                font-size: 14px;
                color: #495057;
                margin-top: 30px;
                box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            }
        </style>
    </head>
    <body>
        {%app_entry%}
        <footer>
            {%config%}
            {%scripts%}
            {%renderer%}
        </footer>
    </body>
</html>
'''

# Modified App layout
app.layout = dbc.Container([
    # Header
    dbc.Row([
        dbc.Col([
            html.H1("â›½ LSTM Fuel Price Prediction Dashboard", className="main-header"),
            html.P("Analyze Historical Data and LSTM Model Predictions",
                   style={'text-align': 'center', 'color': 'white', 'font-size': '1.2rem', 'margin-bottom': '30px'})
        ])
    ]),

    # Country Selection
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("ðŸŒ Select Country for Analysis"),
                dbc.CardBody([
                    dcc.Dropdown(
                        id='country-dropdown',
                        options=[{'label': f"ðŸ³ï¸ {country}", 'value': country} for country in dashboard.get_countries()],
                        placeholder="Choose a country to analyze...",
                        style={'width': '100%', 'fontSize': '16px'}
                    )
                ])
            ])
        ], width=12)
    ], className="mb-4"),

    # New Section for Time Series Graph
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("ðŸ“ˆ Historical Actual vs. LSTM Forecasted (Time Series)"),
                dbc.CardBody([
                    # Fuel Type Dropdown for Time Series Chart
                    dcc.Dropdown(
                        id='fuel-type-dropdown',
                        options=dashboard.get_fuel_types_options(),
                        placeholder="Select Fuel Type",
                        style={'width': '100%', 'fontSize': '16px', 'marginBottom': '20px'}
                    ),
                    dcc.Graph(id='time-series-chart', config={'displayModeBar': True})
                ])
            ])
        ], width=12)
    ], className="mb-4"),

    # Merged Comparison Table (kept as is)
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("ðŸ“ Detailed Comparison: Latest Current Data vs LSTM Predictions"),
                dbc.CardBody([
                    html.Div(id='comparison-table', className="dash-table-container")
                ])
            ])
        ], width=12)
    ], className="mb-4"),


    # Footer
    dbc.Row([
        dbc.Col([
            html.Div([
                html.Strong("ðŸ“Š Data Source: "), "Global Fuel Price Benchmark Database", html.Br(),
                html.Strong("ðŸ¤– Model: "), "LSTM Neural Network for Time Series Prediction", html.Br(),
                html.Strong("âš ï¸ Disclaimer: "), "This dashboard compares historical fuel price data with LSTM model predictions. The LSTM model was trained on historical data and predictions may not reflect actual future prices. This dashboard is designed for analytical and educational purposes.",
                html.Br(), html.Br(),
                html.Small("Â© 2025 LSTM Fuel Price Analysis Dashboard - Machine Learning Comparison Platform")
            ], className="disclaimer")
        ])
    ])

], fluid=True)

# Callback for the detailed comparison table
@app.callback(
    Output('comparison-table', 'children'), # Only one output now
    Input('country-dropdown', 'value')
)
def update_snapshot_dashboard(selected_country):
    if not selected_country:
        return html.Div("Please select a country to view detailed comparison.",
                         style={'color': '#6c757d', 'textAlign': 'center', 'padding': '20px'})

    try:
        comparison_df = dashboard.create_comparison_table(selected_country)
        if not comparison_df.empty:
            style_data_conditional = []
            for i in range(len(comparison_df)):
                if 'Current Price Change (%)' in comparison_df.columns:
                    current_val = comparison_df.iloc[i]['Current Price Change (%)']
                    if pd.notna(current_val) and current_val != '':
                        try:
                            numeric_val = float(str(current_val).replace('%', ''))
                            color = '#28a745' if numeric_val > 0 else ('#dc3545' if numeric_val < 0 else '#6c757d')
                            style_data_conditional.append({
                                'if': {'row_index': i, 'column_id': 'Current Price Change (%)'},
                                'color': color, 'fontWeight': 'bold'
                            })
                        except: pass
                if 'LSTM Forecasted (%)' in comparison_df.columns:
                    lstm_val = comparison_df.iloc[i]['LSTM Forecasted (%)']
                    if pd.notna(lstm_val) and lstm_val != '':
                        try:
                            numeric_val = float(str(lstm_val).replace('%', ''))
                            color = '#28a745' if numeric_val > 0 else ('#dc3545' if numeric_val < 0 else '#6c757d')
                            style_data_conditional.append({
                                'if': {'row_index': i, 'column_id': 'LSTM Forecasted (%)'},
                                'color': color, 'fontWeight': 'bold'
                            })
                        except: pass
            comparison_table = dash_table.DataTable(
                data=comparison_df.to_dict('records'),
                columns=[{"name": i, "id": i} for i in comparison_df.columns],
                style_cell={'textAlign': 'center', 'padding': '12px', 'fontSize': '14px',
                            'fontFamily': 'Segoe UI', 'whiteSpace': 'normal', 'height': 'auto'},
                style_header={'backgroundColor': '#667eea', 'color': 'white', 'fontWeight': 'bold', 'fontSize': '16px'},
                style_data_conditional=style_data_conditional, page_size=10
            )
        else:
            comparison_table = html.Div("No comparison data available for this country.",
                                         style={'color': '#6c757d', 'textAlign': 'center', 'padding': '20px'})
        return comparison_table
    except Exception as e:
        print(f"Error in update_snapshot_dashboard callback: {e}")
        return html.Div(f"An error occurred: {e}", style={'color': 'red'})


# NEW CALLBACK for the Time Series Chart
@app.callback(
    Output('time-series-chart', 'figure'),
    [Input('country-dropdown', 'value'),
     Input('fuel-type-dropdown', 'value')]
)
def update_time_series_chart(selected_country, selected_fuel_type):
    empty_ts_fig = go.Figure()
    empty_ts_fig.update_layout(
        title="Please select a country and fuel type to view time series",
        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
        font=dict(color='#2c3e50'), xaxis={'visible': False}, yaxis={'visible': False},
        annotations=[{'text': "ðŸ“Š Select a country and fuel type to see historical vs. forecasted trends.",
                      'xref': "paper", 'yref': "paper", 'x': 0.5, 'y': 0.5, 'xanchor': 'center', 'yanchor': 'middle',
                      'showarrow': False, 'font': {'size': 16, 'color': '#6c757d'}}]
    )

    if not selected_country or not selected_fuel_type:
        return empty_ts_fig

    try:
        ts_fig = dashboard.create_time_series_chart(selected_country, selected_fuel_type)
        return ts_fig
    except Exception as e:
        print(f"Error in update_time_series_chart callback: {e}")
        error_ts_fig = go.Figure()
        error_ts_fig.update_layout(
            title="An error occurred loading time series chart",
            paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='red'), xaxis={'visible': False}, yaxis={'visible': False},
            annotations=[{'text': f"ðŸš« Error: {e}", 'xref': "paper", 'yref': "paper",
                          'x': 0.5, 'y': 0.5, 'xanchor': 'center', 'yanchor': 'middle', 'showarrow': False,
                          'font': {'size': 14, 'color': 'red'}}])
        return error_ts_fig


if __name__ == '__main__':
    # For running in Google Colab (to get the clickable link and interactive debugging)
    # Ensure 'app' is an instance of JupyterDash for 'mode' to work
    app.run(debug=True, mode='inline')